import numpy as np

from panda_gym.utils import distance


def place_object_reward_function(
    self, object_position, object_goal_position, collision_map, combined_reward
):
    # Reward for moving the object closer to the goal position:
    distance_to_goal = np.linalg.norm(object_position - object_goal_position)
    combined_reward += 20 * (1 - np.tanh(distance_to_goal))
    
    # Fine-tuned reward for finger contact while lifting:
    if collision_map.get("right_finger_contact") and collision_map.get("left_finger_contact"):
        combined_reward += 20  # reward if both fingers make inside contact during the lift

    # Bonus for placing the object correctly at the goal:
    if distance_to_goal < self.distance_threshold:
        self.episode_task_completions_map["place_object"] = True  # Mark the place task as completed
        
        combined_reward += 5000  # Large reward for placing the object at the goal
        print("High reward: Object successfully placed at the goal. Reward: 5000")

    return combined_reward


def lift_object_reward_function(
    self, object_position, object_goal_position, collision_map, combined_reward
):
    # Fine-tuned reward for finger contact while lifting:
    if collision_map.get("right_finger_contact") and collision_map.get("left_finger_contact"):
        combined_reward += 5  # reward if both fingers make inside contact during the lift
        
    elif collision_map.get("right_finger_contact") or collision_map.get("left_finger_contact"):
        combined_reward += 3  # reward for one finger inside contact during the lift

    # Further fine-tuned reward for general finger contact:
    if collision_map.get("both_fingers_contact"):
        combined_reward += 2  # reward for any general contact with the object
    elif collision_map.get("general_finger_contact"):
        combined_reward += 1  # reward for trying even if no contact is made

    # Reward for increasing the object's height:
    if object_position[2] > self.object_max_height + 0.001:
        self.object_max_height = object_position[2]
        combined_reward += 10  # reward for reaching new heights with the object

    # Modify this section: Check if the object has been lifted high enough for placement:
    if object_position[2] >= object_goal_position[2]:
        self.episode_task_completions_map["lift_object"] = True  # Mark the lifting task as completed
        combined_reward += 500  # Large reward for successfully completing the lift
        print("High reward: Object successfully lifted. Reward: 500")

    return combined_reward


def grasp_object_reward_function(
    self, ee_position, object_position, collision_map, combined_reward
):
    # Calculate distance between the end-effector and the object
    distance_to_object = np.linalg.norm(ee_position - object_position)

    # Provide relative reward based on the distance to the object (closer = bigger reward)
    combined_reward += 0.25 * (1 - np.tanh(distance_to_object))

    # Fine-tuned rewards based on finger contact:
    if collision_map.get("object_between_fingers"):
        if collision_map.get("both_fingers_contact"):
            self.episode_task_completions_map["grasp_object"] = True  # Mark the grasp task as completed
            
            combined_reward += 250  # Large reward if both fingers are fully inside the object grip
            
            print("High reward: Object successfully grasped. Reward: 250")
        elif collision_map.get("right_finger_contact") or collision_map.get(
            "left_finger_contact"
        ):
            combined_reward += 3  # reward if only one finger makes full inside contact

    # Further fine-tuned reward for general finger contact:
    if collision_map.get("both_fingers_contact"):
        combined_reward += 2  # reward for any general contact with the object
    elif collision_map.get("general_finger_contact"):
        combined_reward += 1  # reward for trying even if no contact is made

    return combined_reward


def dense_reward(self, object_position, object_goal_position, ee_position, info):
    # print(info)
    combined_reward = 0
    collision_map = info.get("collision_map", {})  # Get the collision map
    # print("collision map:\n")
    # print(collision_map)

    # Call grasping reward function if the robot hasn't grasped the object
    if not self.episode_task_completions_map["grasp_object"]:
        # print("using grab reward function")
        combined_reward += grasp_object_reward_function(
            self, ee_position, object_position, collision_map, combined_reward
        )

    # Call lifting reward function if the object hasn't been lifted yet
    elif not self.episode_task_completions_map["lift_object"]:
        # print("using lift reward function")
        combined_reward += lift_object_reward_function(
            self, object_position, object_goal_position, collision_map, combined_reward
        )

    # Placing
    elif not self.episode_task_completions_map["place_object"]:
        # print("using place reward function")
        combined_reward += place_object_reward_function(
            self, object_position, object_goal_position, collision_map, combined_reward
        )

    reward = combined_reward
    # print("complex_dense_reward: " + str(reward))
    return reward


def simple_dense_reward(object_position, object_goal_position):
    d = distance(object_position, object_goal_position)
    reward = -d.astype(np.float32)
    # print("simple_dense_reward: " + str(reward))
    return reward


def sparse_reward(object_position, object_goal_position, distance_threshold):
    d = distance(object_position, object_goal_position)
    reward = -np.array(d > distance_threshold, dtype=np.float32)
    # print("sparse_reward: " + str(reward))
    return reward
